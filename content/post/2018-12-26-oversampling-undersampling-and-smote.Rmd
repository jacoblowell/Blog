---
title: Oversampling, Undersampling and SMOTE
author: Jacob Lowell
date: '2018-12-26'
slug: oversampling-undersampling-and-smote
categories: []
tags: ["Course Imbalance"]
description: ''
---





```{r , include=FALSE}
 library(tidyverse)
 library(scales)
 lgd <- read_csv("lgd.csv")
library(rpart)
hmeq <- read_csv("hmeq.csv")
#creditcard <- read_csv("creditcard.csv")
#remove(creditcard)
prop.table(table(lgd$event,lgd$purpose1))

table(lgd$event)

table(lgd$event,lgd$purpose1)

prop.table(table(lgd$event))


table(hmeq$BAD)

```



```{r,fig.width = 5,fig.asp = 0.618, fig.align='center'}
hmeq %>%  filter(!is.na(VALUE)) %>%
  ggplot( aes(x = VALUE, y = LOAN , color= factor(BAD))) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue', 'red')) + facet_grid(~BAD) + labs(title = "Home Equity Loan Performance by loan amount and value of home")  +scale_y_continuous(labels = scales::dollar) + scale_x_continuous(labels = scales::dollar)
```

**oversampling, unsersampling**

These programs do not work well with missing values.  They only are able to resample for complete cases.

*** level the dataset ***
```{r}
library(ROSE)

#hmeq <- na.omit(hmeq)
table(hmeq$BAD)

#hmeq <- hmeq %>% mutate(fill_notnull = 1)

hmeq$ID <- seq.int(nrow(hmeq))

# for over and under, missing values skew

# Calculate the required number of cases in the over-sampled dataset
 n_new <- 4771/(1-0.5)  # 4771 is the number of goods (non-bad)

# Over-sample
oversampling_result <- ovun.sample(formula = BAD ~ ., data = hmeq,
                           method = "over", N = n_new, seed = 2019)

# Verify the Class-balance of the over-sampled dataset
oversampled_hmeq <- oversampling_result$data
prop.table(table(oversampled_hmeq$BAD))



oversampled_hmeq %>%  ggplot(aes(x = ID , fill = as.factor(BAD) )) + geom_histogram(binwidth =  1) + facet_grid(~BAD)


hmeq_bad_nona <- hmeq %>%  filter(BAD ==1 ) %>%  drop_na()

unique_over_bad <- oversampled_hmeq %>% filter(BAD == 1)

unique_over_bad <- unique_over_bad %>%  group_by(ID) %>%  slice(1) %>% ungroup()

hmeq_good_nona <- hmeq %>%  filter(BAD ==0 ) %>%  drop_na()

unique_over_good <- oversampled_hmeq %>% filter(BAD == 0)

unique_over_good <- unique_over_good %>%  group_by(ID) %>%  slice(1) %>% ungroup()

```




***undersample***

```{r}
table(hmeq$BAD)

 n_new <- 1189/(0.5)  # 4771 is the number of bads (non-goods)

# Over-sample
undersampling_result <- ovun.sample(formula = BAD ~ ., data = hmeq,
                           method = "under", N = n_new, seed = 2019)

# Verify the Class-balance of the over-sampled dataset
undersampled_hmeq <- undersampling_result$data
prop.table(table(undersampled_hmeq$BAD))

```


# combine over and under sample

```{r}
table(hmeq$BAD)

# Specify the desired number of cases in the balanced dataset and the fraction of fraud cases
n_new <- 10000
bad_fraction <- 0.5

# Combine ROS & RUS!
sampling_result <- ovun.sample(formula = BAD ~ ., data = hmeq,
                               method = "both", N = n_new, p = bad_fraction, seed = 2018)

# Verify the Class-balance of the re-balanced dataset
sampled_hmeq <- sampling_result$data
prop.table(table(sampled_hmeq$BAD))


```


## test dups with both way over and under sample

```{r}

hmeq_bad_nona <- hmeq %>%  filter(BAD ==1 ) %>%  drop_na()

unique_over_bad <- sampled_hmeq %>% filter(BAD == 1)

unique_over_bad <- unique_over_bad %>%  group_by(ID) %>%  slice(1) %>% ungroup()

hmeq_good_nona <- hmeq %>%  filter(BAD ==0 ) %>%  drop_na()

unique_over_good <- sampled_hmeq %>% filter(BAD == 0)

unique_over_good <- unique_over_good %>%  group_by(ID) %>%  slice(1) %>% ungroup()





sampled_hmeq %>%  ggplot(aes(x = ID , fill = as.factor(BAD) )) + geom_histogram(binwidth =  1) + facet_grid(~BAD) + labs(title = "HMEQ BOTH OVER and UNDER"  , caption = "You can see that the underweight class is used a high number of times")


```





#omit nas


### the lgd set has no missing values, so oversampling works as expected

```{r ,fig.width = 5,fig.asp = 0.618, fig.align='center'}

#ll  <- na.omit(lgd)
#hmeq <- na.omit(hmeq)



#############################################################################
library(ROSE)

#hmeq <- na.omit(hmeq)
table(lgd$event)

#hmeq <- hmeq %>% mutate(fill_notnull = 1)

lgd$ID <- seq.int(nrow(lgd))

# for over and under, missing values skew

# Calculate the required number of cases in the over-sampled dataset
 n_new <- 1817/(1-0.5)  # 

# Over-sample
oversampling_result <- ovun.sample(formula = event ~ ., data = lgd,
                           method = "over", N = n_new, seed = 2019)

# Verify the Class-balance of the over-sampled dataset
oversampled_lgd <- oversampling_result$data
prop.table(table(oversampled_lgd$event))



oversampled_lgd %>%  ggplot(aes(x = ID , fill = as.factor(event) )) + geom_histogram(binwidth =  1) + facet_grid(~event) + labs(title = "LGD oversample")
```

```{r  ,fig.width = 5,fig.asp = 0.618, fig.align='center' }



##############################################################################
table(lgd$event)

 n_new <- 728/(0.5)  # 4771 is the number of bads (non-goods)

# Over-sample
undersampling_result <- ovun.sample(formula = event ~ ., data = lgd,
                           method = "under", N = n_new, seed = 2019)

# Verify the Class-balance of the over-sampled dataset
undersampled_lgd <- undersampling_result$data
prop.table(table(undersampled_lgd$event))



undersampled_lgd %>%  ggplot(aes(x = ID , fill = as.factor(event) )) + geom_histogram(binwidth =  1) + facet_grid(~event) + labs(title = "LGD undersample")



```



#smote

```{r}

library(smotefamily)
library(FNN)
#hmeq2 <- na.omit(hmeq)
#table(hmeq2$BAD)

table(lgd$event)

# Set the number of fraud and legitimate cases, and the desired percentage of legitimate cases
n0 <- 727; n1 <- 1817; r0 <- 0.5

# Calculate the value for the dup_size parameter of SMOTE
ntimes <- ((1 - r0) / r0) * (n0 / n1) - 1

# Create synthetic fraud cases with SMOTE
smote_output <- SMOTE(X = lgd , target = lgd$event, K = 3, dup_size = 1.2)

# Make a scatter plot of the original and over-sampled dataset
lgd_smote <- smote_output$data
colnames(lgd_smote)[10] <- "Class"
#prop.table(table(lgd_smote$Class))

ggplot(lgd, aes(x = LTV, y = lgd_time, color = as.factor(event))) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red'))

ggplot(lgd_smote, aes(x = LTV, y = lgd_time, color = Class)) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red'))

```




```{r}
ggplot(lgd, aes(x = LTV, y = lgd_time, color = as.factor(event))) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red')) + facet_wrap(~event , scales = "free")

ggplot(lgd_smote, aes(x = LTV, y = lgd_time, color = Class)) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red'))


```





#######

#smote with missing values dataset hmeq


#no, smote does not like NA's

#smote

```{r}

library(smotefamily)
library(FNN)
#hmeq2 <- na.omit(hmeq)
#table(hmeq2$BAD)

hmeq <- na.omit(hmeq)

table(hmeq$BAD)

# Set the number of fraud and legitimate cases, and the desired percentage of legitimate cases
n0 <- 4771; n1 <- 1189; r0 <- 0.5

# Calculate the value for the dup_size parameter of SMOTE
ntimes <- ((1 - r0) / r0) * (n0 / n1) - 1

# Create synthetic fraud cases with SMOTE
smote_output <- SMOTE(X = hmeq[ , -c(1, 5, 6)] , target = hmeq$BAD, K = 3, dup_size = ntimes)

# Make a scatter plot of the original and over-sampled dataset
hmeq_smote <- smote_output$data
colnames(hmeq_smote)[12] <- "Class"
#prop.table(table(hmeq_smote$Class))

ggplot(hmeq, aes(x = MORTDUE, y = LOAN, color = as.factor(BAD))) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red'))

ggplot(hmeq_smote, aes(x = MORTDUE, y = LOAN, color = Class)) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red'))

```




```{r}

ggplot(hmeq, aes(x = MORTDUE, y = LOAN, color = as.factor(BAD))) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red')) + facet_wrap(~BAD , scales = "free")

ggplot(hmeq_smote, aes(x = MORTDUE, y = LOAN, color = Class)) +
  geom_point() +
  scale_color_manual(values = c('dodgerblue2', 'red'))  + facet_wrap(~Class , scales = "free")


```





#### model


1. split into training and test
2.perform smote on one training set
3. train model on smote and non smote
4. compare performance


```{r , lgd}



# Train the rpart algorithm on the original training set and the SMOTE-rebalanced training set
#model_orig <- rpart(event ~ ., data = train_original)
#model_smote <- rpart(Class ~ ., data = train_oversampled)

# Predict the fraud probabilities of the test cases
#scores_orig <- predict(model_orig, newdata = test, type = "prob")[, 2]
#scores_smote <- predict(model_smote, newdata = test, type = "prob")[, 2]

# Convert the probabilities to classes (0 or 1) using a cutoff value
#predicted_class_orig <- factor(ifelse(scores_orig > 0.5, 1, 0))
#predicted_class_smote <- factor(ifelse(scores_smote > 0.5, 1, 0))

# Determine the confusion matrices and the model's accuracy
# CM_orig <- confusionMatrix(data = predicted_class_orig, reference = test$Class)
# CM_smote <- confusionMatrix(data = predicted_class_smote, reference = test$Class)
# print(CM_orig$table)
# print(CM_orig$overall[1])
# print(CM_smote$table)
# print(CM_smote$overall[1])


```

